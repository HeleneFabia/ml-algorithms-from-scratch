# Building Machine Learning algorithms from scratch 

<p align="center">
  <img width="300" height="250" src="https://cdn.pixabay.com/photo/2020/04/22/09/38/circuits-5076887_960_720.png">
</p>

This repository includes several notebooks in which I built several different ML algorithms with NumPy, including: 

- Linear Regression:
  - one variable (<a href="https://github.com/HeleneFabia/ml-algorithms-from-scratch/blob/master/1-linear-regression.ipynb">Notebook 1</a>)
  - multiple variables (<a href="https://github.com/HeleneFabia/ml-algorithms-from-scratch/blob/master/1-linear-regression.ipynb">Notebook 1</a>)
  - feature normalization (<a href="https://github.com/HeleneFabia/ml-algorithms-from-scratch/blob/master/1-linear-regression.ipynb">Notebook 1</a>)
  - regularization (<a href="https://github.com/HeleneFabia/ml-algorithms-from-scratch/blob/master/5-regularized-linear-regression%2Bbias-variance.ipynb">Notebook 5</a>)
- Logistic Regression
  - binary classification (<a href="https://github.com/HeleneFabia/ml-algorithms-from-scratch/blob/master/2-logistic-regression.ipynb">Notebook 2</a>)
  - multi-class classification (<a href="https://github.com/HeleneFabia/ml-algorithms-from-scratch/blob/master/3-multi-class-classification%2Bneural-networks.ipynb">Notebook 3</a>)
  - regularization (<a href="https://github.com/HeleneFabia/ml-algorithms-from-scratch/blob/master/2-logistic-regression.ipynb">Notebook 2</a>)
- Neural Networks (<a href="https://github.com/HeleneFabia/ml-algorithms-from-scratch/blob/master/3-multi-class-classification%2Bneural-networks.ipynb">Notebook 3</a> and <a href="https://github.com/HeleneFabia/ml-algorithms-from-scratch/blob/master/4-neural-networks.ipynb">Notebook 4</a>)
- Support Vector Machines (<a href="https://github.com/HeleneFabia/ml-algorithms-from-scratch/blob/master/6-support-vector-machines.ipynb">Notebook 6</a>)
- K-means Clustering (<a href="https://github.com/HeleneFabia/ml-algorithms-from-scratch/blob/master/7-k-means-clustering%2Bprincipal-component-analysis.ipynb">Notebook 7</a>)
- Principal Component Analysis (<a href="https://github.com/HeleneFabia/ml-algorithms-from-scratch/blob/master/7-k-means-clustering%2Bprincipal-component-analysis.ipynb">Notebook 7</a>)
- Anomaly Detection (<a href="https://github.com/HeleneFabia/ml-algorithms-from-scratch/blob/master/8-anomaly-detection%2Brecommender-system.ipynb">Notebook 8</a>)
- Recommender Systems (<a href="https://github.com/HeleneFabia/ml-algorithms-from-scratch/blob/master/8-anomaly-detection%2Brecommender-system.ipynb">Notebook 8</a>)


These notebooks are assignments that form part of the course <a href="https://www.coursera.org/learn/machine-learning?#about">Machine Learning</a> by Stanford University with Andrew Ng, which I concluded in July, 2020. While the notebooks already included some instructions, formulae and code, the code I wrote myself can be found after the following line in each code cell: 

==================== YOUR CODE HERE ====================

<h2> </h2>
Completing the assignments was a steep learning curve for me. Converting the theoretical concepts of the course into code without using any already existing ML libraries led me to thoroughly engage with different ML algorithms. This also allowed me to strengthen my NumPy and Linear Algebra skills, as well as to practice looking for help and guidance whenever I got stuck with an exercise. 

<h2> </h2>
Thank you to Gerges Dib for providing <a href="https://github.com/dibgerge/ml-coursera-python-assignments">the course assignments in Python</a>

